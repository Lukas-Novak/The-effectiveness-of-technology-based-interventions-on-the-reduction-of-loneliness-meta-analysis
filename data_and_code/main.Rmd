---
title: "Revised Meta-analysis of Technology-Based Interventions for Loneliness"
author: "Jana Furstova & Lukas Novak"
date: '2025-12-08'
output:
  html_document:
    toc: true
    toc_float: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.width=10, fig.align='center')
set.seed(48468) # for reproducibility
```

## 1. Setup and Libraries
This chunk loads all necessary R packages for the analysis. The `pimeta` package is used for calculating the robust prediction interval as requested by the reviewer.

```{r packages}
library(tidyverse) # For data manipulation (dplyr, etc.)
library(metafor)   # The core package for meta-analysis
library(pimeta)    # For robust prediction intervals (Nagashima method)
library(knitr)     # For report generation
library(kableExtra)# For creating nice HTML tables
```

## 2. Load and Prepare Data
Here, we load the raw data, merge the pre-post correlations, and apply the necessary study exclusions as described in the manuscript.

```{r load-data}
# Load the two data files
cor_dat <-  readxl::read_xlsx("Data/pre_post_correlations.xlsx")
dat <- read.csv("Data/meta_data.csv")

# This creates a 'Study_name' column in cor_dat that matches the format in the 'dat' file.
cor_dat <- cor_dat %>%
  mutate(Study_name = case_when(
    Author == "Brog et al. (2022)"         ~ "Brog_2022",
    Author == "Hill et al. (2006)"         ~ "Hill_2006",
    Author == "Iyer et al. (2023)"         ~ "Iyer_2023",
    Author == "Karkosz et al. (2024)"      ~ "Karkosz_2024",
    Author == "Robinson et al. (2013)"     ~ "Robinson_2013",
    Author == "Schwindenhammer et al. (2014)" ~ "Schwindenhammer_2014",
    Author == "Shapira et al. (2007)"      ~ "Shapira_2007",
    Author == "Shapira et al. (2021a)"      ~ "Shapira_2021a",
    Author == "Sun (2023)"                 ~ "Sun_2023",
    Author == "Baez et al. (2017)"         ~ "Baez_2017",
    TRUE                                 ~ Author
  ))

# Merge the two datasets using the new, standardized "Study_name" column
analysis_data <- merge(
  dat,
  cor_dat,
  by = "Study_name"
)

# Study Exclusions based on Manuscript Methods
# Exclude studies that are not eligible for the final analysis.
studies_to_exclude <- c("Shapira_2007", "Sun_2023")

analysis_data <- analysis_data %>%
  filter(!Study_name %in% studies_to_exclude)

# Display the final dataset for verification
kable(analysis_data, caption = "Final Dataset for Meta-Analysis") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)
```

## 3. Calculate Between-Group Effect Sizes
We calculate the effect size for each study. The chosen measure is `"SMCC"` (Standardized Mean Change using Change Score standardization), which is ideal for a pre-post design with a control group.

```{r calculate-effect-sizes}
# Calculate within-group standardized mean change for the TREATMENT groups
es_treat <- escalc(
  measure = "SMCC",
  m1i = Treatment_post_Mean,   # Post-intervention mean
  m2i = Treatment_Pre_Mean,      # Pre-intervention mean
  sd1i = Treatment_post_SD,     # Post-intervention SD
  sd2i = Treatment_Pre_SD,       # Pre-intervention SD
  ni = Treatment_Sample_Size,    # Sample size
  ri = Pre_Post_Correlation_Treatment, # Pre-post correlation
  data = analysis_data
)

# Calculate within-group standardized mean change for the CONTROL groups
es_ctrl <- escalc(
  measure = "SMCC",
  m1i = Control_post_Mean,
  m2i = Control_Pre_Mean,
  sd1i = Control_post_SD,
  sd2i = Control_Pre_SD,
  ni = Control_sample_size,
  ri = Pre_Post_Correlation_Control,
  data = analysis_data
)

# The final effect size (yi) for the meta-analysis is the difference between the treatment change and the control change.
# The final variance (vi) is the sum of the two variances (as the groups are independent).
analysis_data$yi <- es_treat$yi - es_ctrl$yi
analysis_data$vi <- es_treat$vi + es_ctrl$vi

# Add study labels for plotting
analysis_data$slab <- analysis_data$Study_name
```

## 4. Perform Meta-Analysis
We run the main random-effects model using the `metafor` package. This model provides the pooled effect estimate and heterogeneity statistics (IÂ², Q) used in the manuscript and forest plot.

```{r run-meta-analysis}
# Run the robust random-effects model (REML + HKSJ)
# This is the primary model for our manuscript
meta_model <- rma(
  yi, vi,
  data = analysis_data,
  method = "REML", # Restricted Maximum-Likelihood is preferred over DL
  test = "knha",   # Hartung-Knapp-Sidik-Jonkman adjustment
  slab = slab
)

# Display the full summary of the model results
# This output contains the pooled effect, heterogeneity stats (I^2, Q), and significance tests.
summary(meta_model)
```

## 5. Generate Outputs for Manuscript

### 5.1. Data for Manuscript Table 2
This chunk extracts the study-level results into a clean table, exactly as needed for the manuscript. This table provides the core quantitative results for each included study.

```{r generate-table-2}
# Create a summary data frame of the results
results_table <- summary(meta_model, digits=3)

# Extract the individual study data into a clean table
table_2_data <- data.frame(
    Study = meta_model$slab,
    SMD = round(meta_model$yi, 3),
    Std_Error = round(sqrt(meta_model$vi), 3),
    Variance = round(meta_model$vi, 3),
    CI_lower = round(results_table$ci.lb, 3),
    CI_upper = round(results_table$ci.ub, 3),
    Z_value = round(meta_model$yi / sqrt(meta_model$vi), 3),
    P_value = round(2 * pnorm(abs(meta_model$yi / sqrt(meta_model$vi)), lower.tail = FALSE), 3)
)

# Print the table in a clean format
kable(table_2_data, row.names = FALSE, caption = "Study-Level Results for Manuscript Table 2") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)
```

### 5.2. Prediction Interval
The prediction interval shows the expected range of true effects in future studies. This has been updated to use the correct syntax for the `pima` function from the `pimeta` package. The method `"boot"` corresponds to the Nagashima et al. (2019) confidence distribution approach.

```{r prediction-interval}
# Calculate and print the 95% prediction interval using the Nagashima et al. method.
# The pima() function takes the effect sizes (y) and standard errors (se) as input.
# The `method = "boot"` argument specifies the parametric bootstrap PI, which is the
# confidence distribution approach from Nagashima et al. (2019).
pi_model <- pima(
  y = analysis_data$yi,
  se = sqrt(analysis_data$vi),
  method = "boot", # Explicitly specify the Nagashima et al. method
)

# Print the results, which include the CI and the PI
print(pi_model)
```

### 5.3. Forest Plot
This is the primary visualization of the meta-analysis results. The text annotation for the prediction interval has been updated to use the values from the correctly calculated `pi_model` object.

```{r forest-plot}
# Forest plot to PDF & SVG
# Adds N(Treatment), N(Control), Weight(%)
# Now includes visual prediction interval diamond (Nagashima method)

# pdf("forest_plot_final.pdf", width = 11, height = 7.5)
svg("forest_plot_final.svg", width = 11, height = 7.5)

k <- meta_model$k
rows_studies <- k:1

# Compute weights (%)
w <- weights(meta_model)
w_perc <- 100 * w / sum(w)

# Build extra columns
ilab_mat <- cbind(
    as.integer(analysis_data$Treatment_Sample_Size),
    as.integer(analysis_data$Control_sample_size),
    sprintf("%.1f", w_perc)
)

# Extract prediction interval values from pimeta
lpi <- if (!is.null(pi_model$lpi)) pi_model$lpi else pi_model$pi.lb
upi <- if (!is.null(pi_model$upi)) pi_model$upi else pi_model$pi.ub

# Forest plot
metafor::forest(
    meta_model,
    
    # Labels
    xlab   = "Standardized Mean Difference (SMD)",
    header = c("Author(s) and Year", "SMD [95% CI]"),
    mlab   = "REML Model (HKSJ)",
    digits = 2,
    cex    = 1.0,
    
    # Layout: make room for 3 columns on the left
    alim   = c(-3, 3),
    xlim   = c(-10.5, 3),
    rows   = rows_studies,
    ylim   = c(-3.9, k + 3),
    
    # Model overlays
    annotate = TRUE,
    addfit   = TRUE,
    addpred  = FALSE,  
    
    # Extra columns
    showweights = FALSE,
    ilab        = ilab_mat,
    ilab.xpos   = c(-7.5, -6.0, -4.5),
    ilab.pos    = 4,
    ilab.lab    = c("N (Treatment)", "N (Control)", "Weight (%)")
)

# Manually add prediction interval diamond (Nagashima method)
# This draws the diamond below the pooled effect diamond
addpoly(x = (lpi + upi)/2,  # Center of the prediction interval
        ci.lb = lpi,         # Lower bound from pimeta
        ci.ub = upi,         # Upper bound from pimeta
        rows = -1.5,         # Changed from -1 to -1.5 for more spacing
        col = "lightgray",   # Fill color
        border = "darkgray", # Border color
        mlab = "Prediction Interval (Nagashima)",  # Label
        cex = 0.9)

# Extra annotations below the plot
par(xpd = NA)
usr <- par("usr")
x_left <- usr[1]

# Heterogeneity
text(
  x = x_left, y = -2.5, pos = 4, cex = 0.9,  # Changed from -1.7 to -2.5
  bquote(paste(
    "Heterogeneity: Q = ", .(round(meta_model$QE, 2)),
    ", df = ", .(meta_model$k - meta_model$p),
    ", p = ", .(format.pval(meta_model$QEp, digits = 2, eps = 0.001)),
    "; ", I^2, " = ", .(round(meta_model$I2, 1)), "%"
  ))
)

dev.off()

```

### 5.4. Publication Bias Analysis
This section remains unchanged and uses the `metafor` model for consistency in bias diagnostics.

```{r publication-bias}
# 1. Funnel Plot
# A symmetric plot suggests no small-study effects (like publication bias)
funnel(meta_model, main = "Funnel Plot for Publication Bias")

# 2. Egger's Regression Test
# A non-significant p-value (p > 0.05) suggests no significant funnel plot asymmetry.
reg_test_results <- regtest(meta_model, model = "rma")
print(reg_test_results)

# 3. Trim and Fill Analysis
# This method estimates the number of potentially missing studies and the adjusted pooled effect.
trimfill_results <- trimfill(meta_model)
summary(trimfill_results)
```

### 5.5. Sensitivity Analysis (Leave-One-Out)
This analysis recalculates the pooled effect by removing one study at a time to see if any single study disproportionately influences the overall result. This section also remains unchanged and uses the `metafor` model.

```{r sensitivity-analysis}
# Perform and print the leave-one-out analysis
leave1out_results <- leave1out(meta_model)
print(leave1out_results)
```
# References: 

Nagashima, K., Noma, H., & Furukawa, T. A. (2019). Prediction intervals for random-effects meta-analysis: a confidence distribution approach. Statistical methods in medical research, 28(6), 1689-1702.
